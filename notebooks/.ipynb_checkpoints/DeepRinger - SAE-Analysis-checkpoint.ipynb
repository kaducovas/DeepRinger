{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import seaborn as sb\n",
    "import cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/root/6.04.16-x86_64-slc6-gcc49-opt/lib/ROOT.py:301: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return _orig_ihook( name, *args, **kwds )\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProc 2.1.2\n"
     ]
    }
   ],
   "source": [
    "import TuningTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,4.8\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#15, 6\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#import statsmodels\n",
    "#from statsmodels.tsa.stattools import adfuller\n",
    "#import statsmodels.api as sm\n",
    "import scipy\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "import keras.callbacks as callbacks\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirout = '/home/webadmin/plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirin = '/home/caducovas/DeepRinger/data/run_layer1/'\n",
    "data10 = np.load(dirin+\"val_Data_sort_6_hidden_neurons_10.npy\")\n",
    "data20 = np.load(dirin+\"val_Data_sort_6_hidden_neurons_20.npy\")\n",
    "data30 = np.load(dirin+\"val_Data_sort_3_hidden_neurons_30.npy\")\n",
    "data40 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_40.npy\")\n",
    "data50 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_50.npy\")\n",
    "data60 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_60.npy\")\n",
    "data70 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_70.npy\")\n",
    "data80 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_80.npy\")\n",
    "data85 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_85.npy\")\n",
    "data90 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_90.npy\")\n",
    "data95 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_95.npy\")\n",
    "data100 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_100.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirin = '/home/caducovas/DeepRinger/data/'\n",
    "data77 = np.load(dirin+\"val_Data_sort_6_hidden_neurons_77.npy\")\n",
    "data87 = np.load(dirin+\"val_Data_sort_6_hidden_neurons_87.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "print np.array_equal(data77,data87) ,np.array_equal(data40,data10) #,np.array_equal(data10,data40),np.array_equal(data10,data50),np.array_equal(data10,data60),np.array_equal(data10,data70),np.array_equal(data10,data80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False True True True True True\n"
     ]
    }
   ],
   "source": [
    "print np.array_equal(data10,data20),np.array_equal(data10,data30),np.array_equal(data10,data40),np.array_equal(data10,data50),np.array_equal(data10,data60),np.array_equal(data10,data70),np.array_equal(data10,data80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031096699\n",
      "0.031096699\n",
      "0.031096699\n",
      "0.031096699\n",
      "0.031096699\n",
      "0.031096699\n",
      "0.031096699\n",
      "80 0.031096699\n",
      "0.031096699\n",
      "0.031096699\n",
      "0.031096699\n",
      "0.031096699\n"
     ]
    }
   ],
   "source": [
    "print data10[1000][10]\n",
    "print data20[1000][10]\n",
    "print data30[1000][10]\n",
    "print data40[1000][10]\n",
    "print data50[1000][10]\n",
    "print data60[1000][10]\n",
    "print data70[1000][10]\n",
    "print \"80\",data80[1000][10]\n",
    "print data85[1000][10]\n",
    "print data90[1000][10]\n",
    "print data95[1000][10]\n",
    "print data100[1000][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = np.load(dirin+\"val_Data_sort_0_hidden_neurons_77.npy\")\n",
    "data1 = np.load(dirin+\"val_Data_sort_1_hidden_neurons_77.npy\")\n",
    "data2 = np.load(dirin+\"val_Data_sort_2_hidden_neurons_77.npy\")\n",
    "data3 = np.load(dirin+\"val_Data_sort_3_hidden_neurons_77.npy\")\n",
    "data4 = np.load(dirin+\"val_Data_sort_4_hidden_neurons_77.npy\")\n",
    "data5 = np.load(dirin+\"val_Data_sort_5_hidden_neurons_77.npy\")\n",
    "data6 = np.load(dirin+\"val_Data_sort_6_hidden_neurons_77.npy\")\n",
    "data7 = np.load(dirin+\"val_Data_sort_7_hidden_neurons_77.npy\")\n",
    "data8 = np.load(dirin+\"val_Data_sort_8_hidden_neurons_77.npy\")\n",
    "data9 = np.load(dirin+\"val_Data_sort_9_hidden_neurons_77.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import TuningTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(dirin+\"/tunedDiscr.pp-N1-AE_77.hn0010.s0000.il0000.iu0099.et0002.eta0000.pic\",'r')\n",
    "#f = open(dirin+\"/run_layer1/tunedDiscr.pp-N1-AE_80.hn0010.s0005.il0000.iu0099.et0002.eta0000.pic\",'r')\n",
    "\n",
    "a = pickle.load(f)\n",
    "f.close()\n",
    "#g = open(\"/home/caducovas/DeepRinger/data/tunedDiscr.pp-N1-AE_82.hn0010.s0004.il0000.iu0099.et0002.eta0000.pic\",'r')\n",
    "#b = cPickle.load(g)\n",
    "#g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_normslist',\n",
       " '_afternorm',\n",
       " '_beforenorm',\n",
       " '__module',\n",
       " '__version',\n",
       " 'class',\n",
       " '_cnvObj']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['tunedPP']['items'][0]['items'][0].keys()#['__module']\n",
    "#a['tunedPP']['items'][0]['items'][0].keys()#['__module']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/scratch/22061a/caducovas/caloNN/run_layer1/85_run_all/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# Estimating PDF\n",
    "def EstPDF(data, bins=np.array([-1,0, 1]), mode='hist', kernel='epanechnikov', kernel_bw=0.01, verbose=False):\n",
    "    # kernels = 'epanechnikov','gaussian', 'tophat','exponential', 'linear', 'cosine'\n",
    "    if mode == 'hist':\n",
    "        if verbose:\n",
    "            print 'EstPDF: Histogram Mode'\n",
    "        [y,pts] = np.histogram(data,bins=100,density=True)\n",
    "        bins_centers = pts[0:-1]+np.diff(pts)\n",
    "        pdf = y*np.diff(pts)\n",
    "        return [pdf,bins_centers]\n",
    "    if mode == 'kernel':\n",
    "        if verbose:\n",
    "            print 'EstPDF: Kernel Mode'\n",
    "        if kernel is None:\n",
    "            if verbose:\n",
    "                print 'No kernel defined'\n",
    "            return -1\n",
    "        if kernel_bw is None:\n",
    "            if verbose:\n",
    "                print 'No kernel bandwidth defined'\n",
    "            return -1\n",
    "        kde = (KernelDensity(kernel=kernel,algorithm='auto',bandwidth=kernel_bw).fit(data))\n",
    "        aux_bins = bins\n",
    "        log_dens_x = (kde.score_samples(aux_bins[:, np.newaxis]))\n",
    "        pdf = np.exp(log_dens_x)\n",
    "        pdf = pdf/sum(pdf)\n",
    "        bins_centers = bins\n",
    "        return [pdf,bins_centers]\n",
    "\n",
    "# Computing KL Divergence\n",
    "def KLDiv(p, q, bins=np.array([-1,0, 1]), mode='hist', kernel='epanechnikov', kernel_bw=0.1, verbose=False):\n",
    "    [p_pdf,p_bins] = EstPDF(p, bins=bins, mode=mode, kernel=kernel, kernel_bw=kernel_bw, verbose=verbose)\n",
    "    [q_pdf,q_bins] = EstPDF(q, bins=bins, mode=mode, kernel=kernel, kernel_bw=kernel_bw, verbose=verbose)\n",
    "    #print len(p_pdf),len(q_pdf)\n",
    "    kl_values = []\n",
    "    for i in range(len(p_pdf)):\n",
    "        if p_pdf[i] == 0 or q_pdf[i] == 0 :\n",
    "            kl_values = np.append(kl_values,0)\n",
    "        else:\n",
    "            kl_value = np.abs(p_pdf[i]*np.log10(p_pdf[i]/q_pdf[i]))\n",
    "            if np.isnan(kl_value):\n",
    "                kl_values = np.append(kl_values,0)\n",
    "            else:\n",
    "                kl_values = np.append(kl_values,kl_value)\n",
    "    return [np.sum(kl_values),kl_values]\n",
    "\n",
    "# Computing KL Divergence\n",
    "def KLDiv_conj(p, q, bins=np.array([-1,0, 1]), mode='hist', kernel='epanechnikov', kernel_bw=0.1, verbose=False):\n",
    "    p_pdf_conj=1\n",
    "    q_pdf_conj=1\n",
    "    for i_anel in range(100): \n",
    "        [ppdf,p_bins] = EstPDF(p[i_anel], bins=bins, mode=mode, kernel=kernel, kernel_bw=kernel_bw, verbose=verbose)\n",
    "        [qpdf,q_bins] = EstPDF(q[i_anel], bins=bins, mode=mode, kernel=kernel, kernel_bw=kernel_bw, verbose=verbose)\n",
    "    \n",
    "        p_pdf_conj = p_pdf_conj*ppdf\n",
    "        q_pdf_conj = q_pdf_conj*qpdf\n",
    "    \n",
    "    p_pdf=p_pdf_conj\n",
    "    q_pdf=q_pdf_conj\n",
    "    \n",
    "    #print len(p_pdf),len(q_pdf)\n",
    "    kl_values = []\n",
    "    for i in range(len(p_pdf)):\n",
    "        if p_pdf[i] == 0 or q_pdf[i] == 0 :\n",
    "            kl_values = np.append(kl_values,0)\n",
    "        else:\n",
    "            kl_value = np.abs(p_pdf[i]*np.log10(p_pdf[i]/q_pdf[i]))\n",
    "            if np.isnan(kl_value):\n",
    "                kl_values = np.append(kl_values,0)\n",
    "            else:\n",
    "                kl_values = np.append(kl_values,kl_value)\n",
    "    return [np.sum(kl_values),kl_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08329872521110075\n"
     ]
    }
   ],
   "source": [
    "pdf,bins = KLDiv(data77.T,data30.T)\n",
    "print pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339519, 100)\n",
      "(339519, 100)\n",
      "(339521, 100)\n",
      "(339519, 100)\n"
     ]
    }
   ],
   "source": [
    "print data77.shape\n",
    "print data87.shape\n",
    "print data40.shape\n",
    "print data10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6241268774152477"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf,bins = EstPDF(val_data.T[84], verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
